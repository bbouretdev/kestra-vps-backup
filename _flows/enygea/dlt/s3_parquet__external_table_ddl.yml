id: s3_parquet__external_table_ddl
namespace: enygea.dlt

tasks:
- id: run_pipeline
  type: io.kestra.plugin.scripts.python.Script
  taskRunner:
    type: io.kestra.plugin.scripts.runner.docker.Docker
  containerImage: python:3.11-slim
  beforeCommands:
    - pip install --upgrade pip
    - pip install duckdb pyarrow boto3
  env:
    AWS_ACCESS_KEY_ID: "SCWB3XMCCXHTNQC5KQQH"
    AWS_SECRET_ACCESS_KEY: "764e1512-586c-4cbd-ad83-8251a0d27b7c"
  outputFiles:
      - query.sql
  script: |
    import duckdb
    import os
    
    # =========================
    # CONFIG
    # =========================
    
    S3_ENDPOINT = "https://s3.fr-par.scw.cloud"
    S3_REGION = "fr-par"
    
    S3_BUCKET = "sandbox-datalake-bronze"
    S3_PREFIX = "bronze_dlt/notion/workflow_management/sprints"
    
    TRINO_CATALOG = "hive_json_scw"
    TRINO_SCHEMA = "notion"
    TRINO_TABLE = "sprints_bronze"
    
    # =========================
    # DUCKDB CONNECTION
    # =========================
    
    con = duckdb.connect(database=":memory:")
    
    con.execute("INSTALL httpfs;")
    con.execute("LOAD httpfs;")
    
    con.execute(f"""
    SET s3_endpoint='s3.fr-par.scw.cloud';
    SET s3_url_style='path';
    SET s3_use_ssl=true;
    SET s3_region='fr-par';
    SET s3_access_key_id='{os.environ["AWS_ACCESS_KEY_ID"]}';
    SET s3_secret_access_key='{os.environ["AWS_SECRET_ACCESS_KEY"]}';
    """)
    
    # =========================
    # DESCRIBE PARQUET
    # =========================

    parquet_path = f"s3://{S3_BUCKET}/{S3_PREFIX}/*.parquet"
    
    describe_query = f"""
    DESCRIBE
    SELECT *
    FROM read_parquet('{parquet_path}')
    """
    
    schema = con.execute(describe_query).fetchall()
    
    # schema = [(column_name, duckdb_type, null, key, default, extra), ...]
    
    # =========================
    # TYPE MAPPING DuckDB â†’ Trino
    # =========================
    
    def duckdb_to_trino(duck_type: str) -> str:
        t = duck_type.upper()
    
        if t.startswith("VARCHAR") or t == "STRING":
            return "VARCHAR"
        if t.startswith("BIGINT") or t.startswith("INTEGER"):
            return "BIGINT"
        if t.startswith("DOUBLE") or t.startswith("FLOAT"):
            return "DOUBLE"
        if t.startswith("BOOLEAN"):
            return "BOOLEAN"
        if t.startswith("TIMESTAMP"):
            return "TIMESTAMP"
        if t.startswith("DATE"):
            return "DATE"
        if t.startswith("STRUCT") or t.startswith("MAP") or t.startswith("LIST"):
            return "JSON"
        if t.startswith("DECIMAL"):
            return "DECIMAL"
    
        # fallback Bronze-safe
        return "VARCHAR"
    
    # =========================
    # GENERATE TRINO SQL
    # =========================
    
    columns_sql = ",\n    ".join(
        f"{col} {duckdb_to_trino(dtype)}"
        for col, dtype, *_ in schema
    )
    
    sql = f"""
    CREATE TABLE {TRINO_CATALOG}.{TRINO_SCHEMA}.{TRINO_TABLE} (
        {columns_sql}
    )
    WITH (
        format = 'PARQUET',
        external_location = 's3a://{S3_BUCKET}/{S3_PREFIX}'
    );
    """
    
    print("====== GENERATED TRINO SQL ======")
    print(sql)

    with open("query.sql", "w") as f:
          f.write(sql)