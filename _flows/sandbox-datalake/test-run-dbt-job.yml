id: test-run-dbt-job
namespace: sandbox-datalake

tasks:
  - id: dbt
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: clone_repository
        type: io.kestra.plugin.git.Clone
        url: https://github.com/bbouretdev/dbt-sandbox-datalake.git
        branch: master
      - id: dbt_core
        type: io.kestra.plugin.dbt.cli.DbtCLI
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
        # beforeCommands:
        #   - pip install duckdb dbt-core dbt-duckdb
        containerImage: ghcr.io/kestra-io/dbt-duckdb:latest
        profiles: |
          sandbox_datalake:
            outputs:
              dev:
                type: duckdb
                path: ":memory:"
                threads: 16
                extensions: 
                  - httpfs
                  - parquet
                settings:
                  s3_region: "fr-par"
                  s3_access_key_id: "SCWB3XMCCXHTNQC5KQQH"
                  s3_secret_access_key: "{{ secret('SCALEWAY_SECRET_KEY_ID') }}"
                  s3_endpoint: "s3.fr-par.scw.cloud"
            target: dev
        commands:
          - dbt deps
          - >
            dbt run --select tickets sprints points tickets_sprints
            --vars '{"notion_date": "2025-05-17"}'